{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from docx import Document\n",
    "from bs4 import BeautifulSoup\n",
    "from TXT import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from 21BCE317_Vanzara Rajat.pdf:\n",
      "RAJAT VANZARA\n",
      "\n",
      "oJ +91-9662652679 Grajatv.work@gmail.com fj https://www.linkedin.com/in/rajatvanzara/ ©) github.com/rajat120204\n",
      "\n",
      "Education\n",
      "\n",
      "Institute of Technology, Nirma University Sep. 2021 — June 2025\n",
      "Bachelor of Technology in Computer Science and Engineering Ahmedabad, Gujarat\n",
      "CGPA: 8.3\n",
      "\n",
      "Nirma University Sep. 2023 — June 2025\n",
      "Minor in Finance Ahmedabad, Gujarat\n",
      "\n",
      "Relevant Coursework\n",
      "\n",
      "¢ Data Structures e Operating Systems e Programming for e Computer Architecture\n",
      "e Object Oriented e Database Management Scientific Computing e Machine Learning\n",
      "Programming Systems e Computer Networks\n",
      "Projects\n",
      "Financial Crisis Classification | Python, Machine Learning October 2023\n",
      "\n",
      "e Generated a dataset using pandas of 150 different countries and their various features.\n",
      "e Implemented Machine Learning models like RNN and LSTM.\n",
      "e Also used Grid Search for implementing SVM and Decision Tree algorithms.\n",
      "\n",
      "Gesture Based Python Scripts | Python, MediaPipe, OpenCV May 2023\n",
      "¢ Developed using Python.\n",
      "e Implemented scripts to use MediaPipe and OpenCV to control OS functions like controlling volume using gestures.\n",
      "e Created AirCanvas, that enables you to draw on screen using webcam video stream.\n",
      "e Created Volume Gesture Control that enables you to control volume of your system using gestures.\n",
      "\n",
      "Student ID Card Generator | Java, Swing, OOP October 2022\n",
      "¢ Implemented using swing library in JAVA.\n",
      "\n",
      "e Used various OOP concepts like Inheritance, Encapsulation, etc. and also Exception Handling and File Handling\n",
      "concepts of Java.\n",
      "\n",
      "Shopping Website | HTML, CSS, Javascript, Bootstrap May 2023\n",
      "e Developed using HTML, CSS, Javascript and Bootstrap.\n",
      "e Website consisted of different modules like Login Page, Product Page, Register Page.\n",
      "\n",
      "Skills\n",
      "\n",
      "Programming Languages: Python, Java, C, C++, HTML/CSS, JavaScript, SQL\n",
      "Others: Competitive Programming, Communication, Marketing, Management\n",
      "\n",
      "Achievements\n",
      "\n",
      "Pupil on Codeforces (Max Rating: 1261) (rajat_1202)\n",
      "\n",
      "3-star on CodeChef (rajat_1202)\n",
      "\n",
      "Educational Codeforces Round 148 (Div 2)-Global Rank: 2195\n",
      "Educational Codeforces Round 150 (Div 2)-Global Rank: 2515\n",
      "\n",
      "Leadership / Extracurricular\n",
      "\n",
      "Computer Society of India September 2023 — Present\n",
      "General Secretary Nirma University\n",
      "¢ Took sessions for contests-upsolving.\n",
      "e Designed and tested problems for various contests organised on various online judges.\n",
      "e Main lead in organizing events like CUBIX’23 and HackNUthon 4.0.\n",
      "e Took orientation sessions on-campus for juniors explaining them the club activities.\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from 21bce322_Vatsal Vipul Shah.pdf:\n",
      "VATSAL SHAH\n",
      "\n",
      "7041164260 eg\n",
      "\n",
      "vatsal.shah2304@gmail.com ©\n",
      "\n",
      "Software Developer\n",
      "\n",
      "Ahmedabad fr)\n",
      "\n",
      "LinkedIn [fj\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "Diligent problem-solver and coding enthusiast with a keen interest in finance. Mastering Data Structures and\n",
      "Algorithms to unravel intricate puzzles in the digital realm. Seeking to apply my analytical prowess and coding\n",
      "skills, creating smart solutions that redefine the future of finance. Passionate about leveraging technology to\n",
      "drive innovation and optimize financial processes, with a strong commitment to continuous learning and staying\n",
      "at the forefront of advancements in both finance and technology.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Nirma University\n",
      "\n",
      "2021-2025\n",
      "\n",
      "B.tech in Computer Science and Engineering\n",
      "CGPA : 8.61\n",
      "\n",
      "Nirman High School\n",
      "\n",
      "2019-2021\n",
      "\n",
      "Secured 92.8% in 12th CBSE\n",
      "JEE Mains percentile: 98.3\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Proficient in C, C++, Java, Python, and\n",
      "JavaScript, with a strong understanding of\n",
      "Data Structures and Algorithms.\n",
      "Knowledgeable in Computer Vision, applying\n",
      "expertise to develop innovative solutions.\n",
      "Experienced in Object-Oriented\n",
      "Programming, employing best practices for\n",
      "efficient code development.\n",
      "\n",
      "Skilled in integrating and working with\n",
      "Spotify and YouTube APIs to create user\n",
      "applications\n",
      "\n",
      "Strong leadership abilities and problem-\n",
      "solving skills in project management and\n",
      "hackathon\n",
      "\n",
      "HACKATHONS\n",
      "\n",
      "e Participated in HackNuThon, an offline\n",
      "\n",
      "hackathon, building an app for contact\n",
      "information exchange using QR codes\n",
      "\n",
      "Participated in Soft Code Hack 1.0, an online\n",
      "hackathon organized by Phicsit, developed\n",
      "innovative solutions to real-world challenges..\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Air Canvas\n",
      "\n",
      "Innovative project leveraging OpenCV and Mediapipe to\n",
      "craft an interactive finger-drawing surface. Empowering\n",
      "\n",
      "users to express creativity through intuitive hand gestures.\n",
      "\n",
      "Redefining digital art experiences with real-time tracking\n",
      "and visual precision.\n",
      "\n",
      "GitHub:\n",
      "\n",
      "https: //github.com /spacecowbye /Air-canvas\n",
      "\n",
      "PlaylistGrabMP3\n",
      "\n",
      "PlaylistGrabMP3 is a Python script designed to seamlessly\n",
      "transform a Spotify playlist into a curated list of YouTube\n",
      "video links associated with the playlist's songs.\n",
      "\n",
      "Utilizing the Spotipy library to interact with the Spotify\n",
      "Web API and Pytube library for YouTube Data API\n",
      "integration, the script empowers users to download\n",
      "corresponding audio tracks as MP3 files easily.\n",
      "\n",
      "Helps users to download songs offline as mp3 files without\n",
      "the need of Spotify Premium\n",
      "GitHub:\n",
      "https: //github.com /spacecowbye /PlaylistGrab_MP3\n",
      "\n",
      "Gesture-controlled Volume Changer\n",
      "\n",
      "Gesture-Controlled Volume Changer\" is a Python project that\n",
      "utilizes computer vision and hand tracking techniques to\n",
      "control the system's audio volume through hand gestures.\n",
      "\n",
      "By moving the hand closer or farther, users can dynamically\n",
      "adjust the volume, making it a hands-free and intuitive\n",
      "alternative to traditional volume controls.\n",
      "\n",
      "This project showcases my proficiency in computer vision,\n",
      "Python programming, and innovative problem-solving.\n",
      "GitHub:\n",
      "\n",
      "https: / /github.com /spacecowbye /VolumeHandControl\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from Abdullah Resume 2024.pdf:\n",
      "ABDULLAH RANGINWALA\n",
      "\n",
      "+91 7984719884 o Ahmedabad, IN\n",
      "abdullahranginwala28Q@gmail.com © LinkedIn > Github © Leetcode\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "B.Tech in Computer Science and Engineering, Nirma University, Ahmedabad Expected 2025\n",
      "SKILLS\n",
      "\n",
      "Technical Skills Java, Typescript, JavaScript, React, Express, PostgreSQL, Git, MongoDB, Node.js\n",
      "\n",
      "Soft Skills Problem Solving, Communication, Teamwork, Time Management, Adaptability\n",
      "\n",
      "Tools GitHub, Postman, Docker, AWS, Jira\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "Student Developer, Google Summer of Code 2023 May 2023 - Present\n",
      "SCoRE Lab Remote\n",
      "\n",
      "e Led the migration of ImageLab’s front-end from Electron.js to a React and Electron.js architecture, thereby\n",
      "enhancing system performance and user interactivity.\n",
      "\n",
      "e Engineered and integrated React components, and utilized the Blueprint.js UI library for a more responsive and\n",
      "intuitive user interface.\n",
      "\n",
      "e Wrote unit tests covering 100% of the image processing operators and end-to-end tests for the processing pipeline\n",
      "\n",
      "e Reconfigured the backend to function on Node.js and setup inter-process communication between the React and\n",
      "Node.js processes\n",
      "\n",
      "e Exposure: Javascript, React, Electron, OpenCV.js, Node.js\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Bifrost - A Distributed Chat Application\n",
      "\n",
      "e Developed a real-time distributed chat application using WebSockets.\n",
      "\n",
      "e Implemented a messaging queue with Redis Pub/Sub to handle scalable, real-time communication across multiple\n",
      "servers.\n",
      "\n",
      "e Ensured efficient and low-latency message delivery in a distributed system environment.\n",
      "e Tech Stack: TypeScript, WebSockets, Redis, MongoDB, Docker. (Link)\n",
      "\n",
      "Cruise Controller\n",
      "\n",
      "e Developed an npm package that provides a middleware for rate limiting in Express.js applications.\n",
      "\n",
      "e Enhanced security and stability of web applications by preventing excessive requests.\n",
      "\n",
      "e Tech Stack: Javascript, Express.js, Redis. (Link)\n",
      "RhinoRefine - Preprocessor Python Package\n",
      "\n",
      "e Engineered a Python package that streamlines preprocessing tasks for machine learning workflows.\n",
      "e Improved efficiency and accuracy of data preparation, leading to improved model performance.\n",
      "\n",
      "e Tech Stack: Python, Pandas, Numpy, Package Development. (Link)\n",
      "\n",
      "LEADERSHIP AND ACHIEVEMENTS\n",
      "\n",
      "e Invited speaker and panelist at my high school’s developer meet, engaging with students and answering inquiries\n",
      "e Achieved a LeetCode contest rating of 1779, placing in the top 8% of participants worldwide.\n",
      "e Lead of the Web/Mobile team under Google Developer Students Club, Nirma University\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from Charles Obuseh.pdf:\n",
      "Data Engineer charleside2001@yahoo.com_\n",
      "Charles Obuseh, MSc, PE Cypress, TX 77429 * (972)904-3380\n",
      "? ?\n",
      "\n",
      "Self-driven individual, analytical, problem solver with over 3 years leveraging data engineering skills. | am proficient in technical\n",
      "software, languages, and tools with the ability to learn new tools, databases and systems to maintain/enhance strategic vision of\n",
      "the organization and able to provide cutting-edge data engineering skills. Seeking a reputable organization to contribute to with\n",
      "opportunities for personal growth.\n",
      "\n",
      ". TECHNICAL SKILLS\n",
      "\n",
      "Languages Data Manipulation & Databases and Storage\n",
      "e Python, SOL Visualization e AWSRDS, MySQL,\n",
      "Others e Pandas, Tableau BI, ETL, MongoDB, AWS\n",
      "e Git, Bash Apache Spark, Hadoop DynamoDB,\n",
      "\n",
      "HDFS, Snowflake Data SOLAIchemy,\n",
      "\n",
      "PostgreSOL, AWS S3\n",
      "Buckets, SOLite, Azure,\n",
      "Oracle.\n",
      "\n",
      "Factory, SnowSQOL and\n",
      "Snowpipe, Amazon Kinesis\n",
      "Firehose, Databricks, AWS\n",
      "EMR, Athena, Lambda,\n",
      "Amazon MW Apache\n",
      "Airflow and AWS EC2\n",
      "QuickSight and SNS,\n",
      "Cloudera infrastructure —\n",
      "Ambari, Hortonworks\n",
      "Sandbox and Zeppelin\n",
      "Notebook\n",
      "\n",
      "Career Experience\n",
      "\n",
      "Data Engineer | TC Energy | Houston, TX | 09/2019- Present | Odfjell Terminal | Seabrook, TX | 02/2019— 09/2019 | Enterprise\n",
      "\n",
      "Products (Through CF) | Houston, TX | 10/2018 — 02/2019\n",
      "\n",
      "Design and implementation of process data pipeline for asset data migration into AWS cloud environment\n",
      "\n",
      "Built Snowflake Data Pipeline using Amazon Kinesis Firehose starting from the AWS EC2 logs to storage in Snowflake\n",
      "and AWS S3 bucket post-transformation and orchestrating through Amazon Managed Workflows for Apache Airflow\n",
      "(MWAA) DAGs.. Programming language used are Pyspark, Python, SparkSq|\n",
      "\n",
      "Architecting data pipeline with Cloudera infrastructure — Ambari, Hortonworks Sandbox using Zeppelin Notebook.\n",
      "Programming language used are Python, SOL\n",
      "\n",
      "Created DataStream using AWS kinesis DataStream and kinesis firehose. Programming language used are Pyspark,\n",
      "Python, SparkSql\n",
      "\n",
      "Migration solution from SAP and Maximo to Data Lake.\n",
      "\n",
      "Solved data quality issues using AWS Databrew and Apache PySpark on AWS EMR and Databricks on AWS EC2 Clusters\n",
      "for data wrangling and transformations.\n",
      "\n",
      "AWS Project monitoring using AWS Lambda and Aurora\n",
      "Performed SQL data analysis using Oracle Database\n",
      "\n",
      "Regular meeting with stakeholders to gather user requirements and ascertain objectives.\n",
      "\n",
      "Senior Data Analyst | Tesoro Logistics (Through IG) | San Antonio, TX | 04/2017 — 10/2018\n",
      "\n",
      "... continued...\n",
      "\n",
      "e Design and implementation of process data pipeline and loading of structured data for performing quantitative and\n",
      "qualitative asset risk modelling, predictive analysis for program budgeting and forecast.\n",
      "\n",
      "e Created process safety risk reduction metrics\n",
      "\n",
      "Project Engineer | Weatherford | Houston, TX | 09/2013-— 03/2016\n",
      "\n",
      "e Performed ETL of drilling well bottom hole pressure ‘.mbd’ data from field and wireline instrumentations (bottom hole\n",
      "pressure, well depth and true vertical height of drilling bit).\n",
      "\n",
      "e Cleaned and transformed data into a*.csv’ data file. Load data into Weatherford microflux database for analysis.\n",
      "\n",
      "e Project management of secure drilling operations of over 80 wells in Canada, Iraq, Nigeria, Angola, and Cameroon for\n",
      "clients such as Repsol, Shell, Exxon Mobile, Chevron and Total\n",
      "\n",
      "Education & Certifications\n",
      "University of North Texas | Master of Science | Mechanical and Energy Engineering| Denton, TX\n",
      "\n",
      "Rice University | Certificate | Data Analytics | Houston, TX\n",
      "\n",
      "License\n",
      "\n",
      "Licensed Texas Professional Engineer | Texas Board of Professional Engineer and Land Surveyors\n",
      "\n",
      "Additional Skills\n",
      "\n",
      "Excellent project and time manager with outstanding excellent presentation skills, a great team player and ability to extend\n",
      "empathy.\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from documents20220826-1-v01cla.pdf:\n",
      "Ashwini Kalidas Vedula\n",
      "Email ID: ashwini.vedulaQnyu.edu | +1 (201)-616-1347 | LinkedIn: linkedin.com/in/ashwini-vedula\n",
      "Education\n",
      "\n",
      "New York University, New York, NY Sept 2021- May 2023\n",
      "\n",
      "Courant Institute of Mathematical Sciences and Stern School of Business\n",
      "\n",
      "Master of Science in Information Systems - 3.6/4\n",
      "Courses: Dealing with Data, Data Science for Business : ‘Technical, Database Management Systems, Real Time\n",
      "Big Data Analytics, Cloud Computing\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "Databases & Tools : MySQL, SSMS, MS Access, PostgreSQL, PL/SQL, MongoDB\n",
      "Data Analysis & Visualization Tools : Python, R , SQL, MS Excel, Tableau, Power BI\n",
      "\n",
      "Cloud Platforms & Big Data Technologies : AWS (Redshift, EC2, $3, EMR, SageMaker, DynamoDB Table), Azure\n",
      "(Storage, IoT, Virtual Machines), GCP (BigTable, DataLab), Apache Hadoop, Hive\n",
      "\n",
      "Experience\n",
      "Clark Associates Inc Pennsylvania, USA\n",
      "Financial Systems and Data Intern May 2022 - Aug 2022\n",
      "\n",
      "e Extracted data from varied data sources to automate Summary Income financial reports(monthly, quarterly and\n",
      "yearly) for the various subsidiaries of Clark Associates Inc. that reduced manual entry time by 70%.\n",
      "\n",
      "e Collaborated with cross-functional teams to enhance and optimize existing Power BI reports that helped stakeholders\n",
      "analyze the financial performance of their business.\n",
      "\n",
      "Dacapo Brokerage India Private Limited Mumbai,India\n",
      "Senior Analyst Aug 2020 - Jul 2021\n",
      "e Created visualization of daily top gainer/loser index stocks, relative sector performance and analyzed technical trends\n",
      "such as moving average of stock prices to help clients make informed investment decisions.\n",
      "\n",
      "CRISIL Limited, An S&P Global Company Mumbai, India\n",
      "Senior Associate - Data Science & Quants Lab Oct 2019 - Jul 2020\n",
      "e Lead a team of 2 interns to develop reports with functional specifications like KPI metrics, revenue tracking, budget\n",
      "vs. sales to understand opportunities in the sales funnel and improve operational effiency by 50% for the Senior\n",
      "Management of CRISIL’s Business Development Operations Team.\n",
      "\n",
      "Onsite Supply Chain Analytics Project - Doha, Qatar\n",
      "\n",
      "e Created and maintained 6 real time dashboards in Tableau that educated the Wholesale Banking Group on key\n",
      "metrics and performance measures.\n",
      "\n",
      "e Assisted in the design and development of Data Mart, fact tables using MySQL framework to decrease dependency\n",
      "on Tableau for complex calculations thereby reducing the dashboard loading time by 85%.\n",
      "\n",
      "e Exposure dealing with large relational data sets(8 Million+),load and query performance, archiving, stored\n",
      "procedures, etc.\n",
      "\n",
      "e Implemented a heuristic scoring model for approaching and on-boarding prospective customers that boosted\n",
      "conversions by 55%.\n",
      "\n",
      "e Built 31 cross-sell/up-sell rule-based configuration for product recommendations with Prescriptive Analytics.\n",
      "\n",
      "e Engaged with users in testing, release management, and operations to ensure quality of code development,\n",
      "deployment and post-production support.\n",
      "\n",
      "Associate Software Engineer - Data Science €§ Quants Lab Jul 2018 - Oct 2019\n",
      "e Determined sales forecasting for 250+ retainer stores of the biggest conglomerate in UAE using Holt-Winters\n",
      "algorithm.\n",
      "\n",
      "e Analysed data to develop a de-duplication algorithm model for grouping similar occurring brand names together.\n",
      "\n",
      "e Segmented 5 Million+ customers using RFM analysis to help the bank associates determine in advance the nature of\n",
      "future business operations and marketing strategies.\n",
      "\n",
      "e Performed Market Basket Analysis based on frequent purchasing patterns of customers.\n",
      "\n",
      "Leadership and Achievements\n",
      "\n",
      "¢ Conferred Quarterly Award,(Service Excellence Award - Q4 2019) at Crisil Limited.\n",
      "¢ Received CRISILite Award for Performance (CLAP), for the month of May 2019.\n",
      "\n",
      "e Treasurer of Computer Society of India-VESIT Student Chapter for the year 2016-2017.\n",
      "e Executive Head of Sponsorship Committee in the inter-collegiate technical festival.\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from documents20220828-1-1fs1dgp.pdf:\n",
      "UTKARSH SINGH\n",
      "\n",
      "FORBES 30 UNDER 30, JOHNS HOPKINS UNIVERSITY\n",
      "\n",
      "United States | 1048 Galley Lane, Foster City, CA 94404\n",
      "\n",
      "usinghjhu@gmail.com | +1-443-378-3322\n",
      "\n",
      "GitHub.com/utsingh | LinkedIn.com/in/utkarsh-singh-7aab88159\n",
      "\n",
      "https://dronamaps.com, https://dronemaps.com\n",
      "\n",
      "Skills Summary\n",
      "\n",
      "Enterprise UAV Systems Integration, Developing\n",
      "Distributed Enterprise-GIS Systems (ESRI and Open\n",
      "Source), ArcGIS Enterprise, ArcGIS GeoEvent Server,\n",
      "ArcGIS ImageServer , ArcGIS Notebook Server,\n",
      "Geoserver + Mapserver, Linux SysAdmin with Cl/CD\n",
      "enabled DevOps, Computer Vision (Pose Estimation,\n",
      "Structure-from-Motion and GIS 3D Reconstructions\n",
      "on MVS and Poisson Surface Reconstruction\n",
      "pipelines), Geometric Deep Learning for 3D Point\n",
      "Clouds via PointNet, ShapeNet, SyncSpecCNN,\n",
      "YOLO3, Nvidia NERF implementations on UAVs,\n",
      "Databases (SAP HANA, PostGreSQL with PostGIS,\n",
      "MongoDB, Cassandra), HA Virtualization with Hyper-\n",
      "V, Xen, ESXi, AWS/Azure, Containerization with LXC,\n",
      "Docker and Kubernetes on HA ProxMoxVE\n",
      "\n",
      "Boards and Memberships\n",
      "\n",
      "BS Computer Science, June 2022\n",
      "\n",
      "Johns Hopkins University\n",
      "\n",
      "Key Courses: Computational Genomics, Distributed\n",
      "Systems, Computer Vision, Foreign Gene Expression,\n",
      "Practical Cryptographic Systems, Parallel\n",
      "Programming, Artificial Intelligence, Databases,\n",
      "Computer Science Innovation and Entrepreneurship,\n",
      "Forensic Psychology\n",
      "\n",
      "Additional:\n",
      "\n",
      "Advanced Diploma in Data Systems & Analysis,\n",
      "University of Oxford CE\n",
      "\n",
      "Harvard Summer School (Probability)\n",
      "\n",
      "Brown University Pre-College\n",
      "\n",
      "Grade schooling (10th and 12th) with Cambridge\n",
      "International Examinations (GCE A-Level and IGCSE)\n",
      "\n",
      "Confederation of Indian Industries (Cll) Digital Agriculture Committee\n",
      "\n",
      "National Committee on Civil Aviation, Government of India\n",
      "\n",
      "FICCI (Federation of Indian Chambers of Commerce and Industry) Committee on Drones\n",
      "\n",
      "ACM, IEEE, Drone Federation of India\n",
      "\n",
      "DronaMaps Private Limited\n",
      "\n",
      "Founder & CEO / August 2016 to July 2022 — “Continuous & Uninterrupted Rapid 3D Mapping using Drones”\n",
      "\n",
      "Supervisor (Co-founder and Board Member): Ms. Ayushi Mishra amishra@dronamaps.com\n",
      "\n",
      "DronaMaps builds centimeter level accurate 3D Maps using drones. It provides an end-to-end GIS+MIS pipeline for\n",
      "\n",
      "data acquisition, processing, and Al-enabled 4D Spatio-Temporal Change Detection and Analytics.\n",
      "\n",
      "o Designed and implemented a large-scale 3D processing pipeline (for million-scale sqkm of area at a time) based\n",
      "on Structure-from-Motion (SfM) in C++ with CUDA, Poisson Surface Reconstruction and Python based feature-\n",
      "classification and species/feature identification from GeoTIFF & 3D Point-Clouds.\n",
      "\n",
      "o Designed & Deployed On-Prem Production Cluster maintenance with 30,000+ CUDA cores, TB-sclae RAM bare-\n",
      "metal units for photogrammetry and distributed PB block storage for Voxel Cleanups and big-data analysis with\n",
      "\n",
      "HDFS/Spark.\n",
      "\n",
      "Deployed HA Databases to scale out into terabyte-scale geo-databases in SAP HANA / PostgreSQL+PostGIS.\n",
      "Developed Micro and Nano UAVs in partnership with Army Design Bureau, Govt of India. Custom UAVs for GPS-\n",
      "denied environments with Al based autopilot (6x RGB-d cameras) and Edge 3D Sensor Processing (Nvidia\n",
      "Jetson), with autonomous collision-tolerant navigation and optional payloads like Narrowband Multispectral\n",
      "camera for Precision Agriculture, Main Payload Stereo Camera for Indoor/Forest 3D Mapping and Navigation.\n",
      "\n",
      "\n",
      "UTKARSH SINGH\n",
      "\n",
      "DronaMaps builds dashboards that combines GIS and MIS datasets. It brings together the GIS datasets from\n",
      "enterprise GIS workloads (like Geoserver or ESRI ArcGIS Enterprise suite) and integrates them with disparate MIS\n",
      "datasets including SAP based MIS/ERP workloads. Further, satellite and real-time drone data sources are added to\n",
      "it, which gives a wholistic dashboard experience to the user combining all the disparate data sources into a GIS\n",
      "enabled Single Source of Truth to analyze and assist in decision making. DronaMaps is enterprise focused and\n",
      "caters to large-scale B2B and B2G clients and has posted an average 400% growth YoY since 2016.\n",
      "\n",
      "Key Projects and Verticals\n",
      "\n",
      "o URBAN: Deployed India’s largest GIS Command and Control Center for the State Govt of Punjab, India\n",
      "(https://gis.punjab.gov.in). Consists of fully autonomous drone processing pipeline managing autonomous\n",
      "drone deployments across the State of Punjab, full Enterprise Real-Time GIS System for collecting and\n",
      "managing Property Taxes for 23 districts, 250+ Towns Urban data, and Terabyte scale drone and satellite\n",
      "data acquisition and management. Other Clients: Govt of Arunachal Pradesh, India, etc.\n",
      "\n",
      "o PRECISION AGRICULTURE: Using Al based UAV Pest & Disease Detection and Species Identification from\n",
      "RGB-d cameras, built analytics of Temporal Stress Change Detection, Plant Count, Yield Estimation, Carbon\n",
      "Sequestration and leaf-by-leaf Stress Indexing using Near Infra-Red and Red-Edge spectrum cameras.\n",
      "Developed novel indexes like New Leaf Index, and Mature Plant Index for Yield estimation and prediction.\n",
      "Crops: Banana and other Horticulture Crops, Brinjal and Groundnut and Other Vegetable crops.\n",
      "\n",
      "o WATER PIPELINES: Mapped several hundred sqkm of major cities in India to extract Junction Elevation\n",
      "Levels using survey-grade 3D Drone data acquired at absolute accuracy of + 4mm (x,y) and + 9mm (z).\n",
      "\n",
      "o CONSTRUCTION & INDUSTRIAL AREAS: UAV 3D-Maps of large-scale industrial sites with Spatio-\n",
      "Temporal Change Detection and Analytics for construction progress monitoring, centimeter-scale contour\n",
      "extraction, floor counts, encroachment detection & alerts, and booking of properties via the 3D portal.\n",
      "Clients: Govt of Rajasthan, Department of Industries; Madhya Pradesh State Electronics Development\n",
      "Corporation; etc.\n",
      "\n",
      "o AERIAL FOREST SEEDING: Designed, developed, and deployed a custom drone for autonomous large-\n",
      "scale forest area seeding using drones, under a mission to plant million-scale trees rapidly, including in hard-\n",
      "to-reach areas. Clients: Govt of Rajasthan, Department of Forests\n",
      "\n",
      "o HIGHWAYS: Deployed Drone based traffic studies, drone-assisted enforcement, and GIS Change Detection\n",
      "based National Highway Monitoring System using a network of 600+ drone providers.\n",
      "\n",
      "o DISASTER RESPONSE: Regularly deployed Search & Rescue drones with flashlights and Live Feeds to HQ\n",
      "for disaster response with National Disaster Response Force, Govt of India at high-altitude areas and flood\n",
      "areas. Drones equipped with edge Real-time 3D mapping and Al based navigation for GPS-denied\n",
      "environments like tunnels and caves.\n",
      "\n",
      "o RURAL DEVELOPMENT: Deployed large-scale 3D mapping system using drones for village level mapping\n",
      "for Govt of UP, India. Al-based feature extraction for building footprints, roads, wells, ponds, agricultural\n",
      "fields, health of crops, and Statewide village-by-village level analytics.\n",
      "\n",
      "o SECURITY & SURVEILLANCE: Deployed large-scale continuous monitoring for District Police using Live\n",
      "Telecasting Swarm of UAVs and real-time updating 3D map data from drones with RTK-accuracy for\n",
      "monitoring & emergency response of 3 million+ footfall during a festival in the City of Ayodhya, UP, India.\n",
      "\n",
      "o R&D: Led the research team to develop novel drone techniques for Continuous and Uninterrupted Rapid 3D\n",
      "Mapping, and custom Micro and Nano UAVs with Edge Processing capabilities in GPS+Network denied\n",
      "indoor environments.\n",
      "\n",
      "o COVID19 RESPONSE: Deployed COVID tracking dashboards with 1.4million+ DAU for 11 State\n",
      "Governments in India, endorsed by Johns Hopkins University. Developed GlIS-based Quarantine Violation\n",
      "tracking at 10meter scale using cellular networks, and Transmission Dynamics and Disease Spread Analysis.\n",
      "\n",
      "\n",
      "UTKARSH SINGH\n",
      "\n",
      "Enterprise Partnerships\n",
      "\n",
      "O\n",
      "\n",
      "ESRI Inc, USA, Silver Partner (2018-present): Accepted into ESRI Startups Program for custom GIS product\n",
      "development, graduated into Silver Partner, closed combined revenue of 1M+ USD with ESRI India.\n",
      "\n",
      "SAP SE, Germany (2018-present): Accepted into the Co-Innovation Lab (SAP COIL) and executed the SAP\n",
      "PartnerEdge Contract with SAP India Private Limited for co-sales to Enterprises.\n",
      "\n",
      "Kotak Mahindra Bank Limited (2017-present): Executed a multi-year contract for co-selling with KMBL to\n",
      "convert high-value urban sector accounts like that of Municipal Corporations. Co-developed a product under\n",
      "partnership to inspect and assess properties for Loan-Against-Property (LAP) portfolio in Tier 2 and Tier 3\n",
      "towns in India.\n",
      "\n",
      "KPMG India (2020-present): Executed a co-sales partnership for public sector clients, executed partnership\n",
      "to provide Subject Matter Experts for KPMGs UAV projects in the public sector in India.\n",
      "\n",
      "Aditya Birla Group, India (2021): Executed a partnership with ABG for UAV integration into its group\n",
      "companies with a focus on developing custom products for managing & monitoring 250+ mines for cement\n",
      "manufacturing using drone based monitoring & stockpile volumetric assessments.\n",
      "\n",
      "Startup Incubators\n",
      "\n",
      "o US Embassy Nexus Startups (Cohort 7): Incubated by Nexus Startups for the development of Impact\n",
      "focused solutions in drone industry.\n",
      "\n",
      "o Reliance Industries Limited (JioGenNext 2018 batch): Accepted into JioGenNext batch of 2018 and co-\n",
      "developed products for Precision Agriculture.\n",
      "\n",
      "o NASSCOM (Center of Excellence loT and 10K Startups): Accepted into NASSCOM 10k Startups, graduated\n",
      "to NASSCOM Center of Excellence lol. Won NASSCOM Product Conclave 2017, NASSCOM Emerge 50,\n",
      "and NASSCOM Innotrek San Francisco 2018. Signed co-selling for custom drone solutions in public sector.\n",
      "\n",
      "o ACT Grants (2020): Secured $50,000 USD grant for continued deployment of COVID-19 portals for\n",
      "quarantine management and patient-tracking for Government of India.\n",
      "\n",
      "o SINE IIT Bombay (2021): Secured an additional $50,000 USD grant for development of drone solutions for\n",
      "the Urban Vertical for various agencies and departments under Govt of India and MEITY.\n",
      "\n",
      "o Advantage Austria (2022): Accepted into the 2022 batch of Advantage Austria facilitated by the Embassy of\n",
      "Austria, Commercial Division, New Delhi.\n",
      "\n",
      "Awards\n",
      "\n",
      "1. Forbes 30 Under 30 (Asia) — 2020\n",
      "\n",
      "2. Economic Times Innovation Award for Contribution to Al — 2020\n",
      "\n",
      "3. Johns Hopkins Alumni Award, Outstanding Recent Graduates for DronaMaps - 2021\n",
      "\n",
      "4. ESRI Partner of the Year — 2021\n",
      "\n",
      "5. Shield for Distinguished Services, National Disaster Response Force —- 2021\n",
      "\n",
      "6. NASSCOM Emerge 50 - 2020\n",
      "\n",
      "7. YOURSTORY Tech30 — 2020\n",
      "\n",
      "8. Inc42 BIGSHIFT Startups — 2020\n",
      "\n",
      "9. National Startup Award Finalist 2020, India\n",
      "\n",
      "10.World Bank Tech Emerge Resilience — 2020\n",
      "\n",
      "11.Startup of the Year — Business World — 2019\n",
      "\n",
      "12.Startup of the Year — Asia Pacific Week, Berlin — 2019\n",
      "\n",
      "13.ASSOCHAM Young Achiever of the Year — 2019\n",
      "\n",
      "14.ESRI User Conference Geospatial Innovation of the Year — 2018, 2019\n",
      "15.NASSCOM Product Conclave, Product of the Year — 2017\n",
      "\n",
      "\n",
      "UTKARSH SINGH\n",
      "\n",
      "Past Experiences (2011-2016)\n",
      "\n",
      "Johns Hopkins University, Department\n",
      "of IT\n",
      "\n",
      "Assistant System Administrator / August 2015 —\n",
      "January 2016\n",
      "\n",
      "Apple Certified System Repair Technician, Enterprise\n",
      "ADFS and identity management, support tickets and\n",
      "issue tracking for replacement systems, SAN and HA\n",
      "systems for classrooms.\n",
      "\n",
      "Johns Hopkins Medicine\n",
      "\n",
      "Research Assistant / August 2014 — March 2015\n",
      "The Pan Lab — Dr. Duojia Pan\n",
      "\n",
      "Reversal of Hippo-growth pathways in Drosophila for\n",
      "Tumor Reduction. Implemented micro-surgical\n",
      "techniques of organ extraction for Drosophila flies.\n",
      "Performed sample preparation, separation, wing and\n",
      "eye-disc surgical extraction from larvae, and GFP\n",
      "analysis.\n",
      "\n",
      "Freelance Developer\n",
      "2011-16 / “Designed and developed web-application\n",
      "systems with a total of $80,000+ revenue.”\n",
      "\n",
      "Key Projects: DancelnTime web-application system\n",
      "for booking, Internal Employee Application System for\n",
      "LeggMason, Web-Publishing Application for Johns\n",
      "Hopkins Department of Pharmacology, IT Support.\n",
      "\n",
      "Johns Hopkins University, Disability\n",
      "Services\n",
      "Note Taker / October 2012- December 2012\n",
      "\n",
      "Note taking for classes for the JHU Office of Student\n",
      "Disability Services\n",
      "\n",
      "Academic Projects\n",
      "\n",
      "Johns Hopkins Libraries: Public Access\n",
      "Submission System (pass.jhu.edu)\n",
      "Supervised By: Stephen Walli, Principal Program\n",
      "Manager, Azure Office of the CTO\n",
      "\n",
      "Helped develop the Java backend & implemented\n",
      "ElasticSearch and containerization for the JHU PASS\n",
      "system at JHU Libraries.\n",
      "\n",
      "4\n",
      "\n",
      "Beans.org (2015 - 2016)\n",
      "\n",
      "Instructor: Dr. Lawrence Aronhime\n",
      "\n",
      "“Read and get paid”. An NLP based system where\n",
      "each user earns credit-per-minute for interacting with\n",
      "sponsored media content and reading articles.\n",
      "Sponsoring proceeds are distributed intelligently\n",
      "between users based on profile-wise NLP based\n",
      "ranking-score. Android application developed for\n",
      "alpha runs, highest articles paid over $12 per user for\n",
      "2-minute interactions, with an average of around $2\n",
      "per article.\n",
      "\n",
      "New Horizons Pluto Flyby Imagery\n",
      "(Spring 2015)\n",
      "\n",
      "Instructors: K. Lewis, D. Strobel\n",
      "\n",
      "Retrieved, processed and analyzed in lab imagery\n",
      "data from NASA New Horizons Spacecraft during its\n",
      "2015 Pluto Fly-by. Techniques used were\n",
      "photogrammetry, mosaicking, and AT. Monochrome\n",
      "sensor point-wise data was processed into full-color\n",
      "mosaic imagery for publishing.\n",
      "\n",
      "Institute for Data-Intensive Engineering\n",
      "and Science, JHU (Fall 2013)\n",
      "\n",
      "Coordinated and automated application deployment\n",
      "strategies for production machines. Designed and\n",
      "implemented a C#-based web dashboard to provide\n",
      "in-depth data analytics about Office client open/save\n",
      "file telemetry; including performance, usage, and error\n",
      "data aggregation. Updated and maintained critical\n",
      "hardware and software on a 10-petabyte high\n",
      "performance computing cluster (HA).\n",
      "\n",
      "Foreign Gene Expression (Spring 2013)\n",
      "Instructor: Dr. Robert Horner\n",
      "\n",
      "Molecular cloning that allow bacteria to be used to\n",
      "produce a particular gene product. Recombinant\n",
      "plasmids (pMal-p and pMC-1820) carrying a fusion\n",
      "protein gene were used to transform E.Coli and the\n",
      "gene products were isolated.\n",
      "\n",
      "Media Mentions\n",
      "\n",
      "1. Johns Hopkins Newsletter - Hopkins coronavirus-tracking map is the key source for governments and the\n",
      "public\n",
      "\n",
      "2. Johns Hopkins University — Engineering Our Community: Utkarsh Singh and Ayushi Mishra\n",
      "\n",
      "3. The Hindu — 3D Maps at your Fingertips\n",
      "\n",
      "4. The Hindu - NASSCOM Selects 4 Tech Based Startups\n",
      "\n",
      "5. The Hindu — Nasscom CoE-incubated start-ups help combat challenges posed by COVID-19\n",
      "\n",
      "6. Times of India — Safety concerns over two lakh illegal drones in India: Experts\n",
      "\n",
      "7. Times of India - BBMP drones to survey properties in five wards\n",
      "\n",
      "8. Niti Aayog, Govt of India, PIB: Empowered Group 6 Engages CSOs/NGOs/Industry/Intl Organisations in\n",
      "India’s fight against COVID-19\n",
      "\n",
      "9. Yourstory —DronaMaps\n",
      "\n",
      "10. Yourstory — [Tech30] Drona Maps’ drone tech collects and digests data to provide decision-makers with\n",
      "usable insights\n",
      "\n",
      "11. Yourstory - How Drona Maps is using drones to create 3D maps of cities in India to track COVID-19 hotspots\n",
      "\n",
      "12. Yourstory — ‘The Future is now’ says startups on how COVID-19 has accelerated changes in market\n",
      "dynamics\n",
      "\n",
      "13. Business Standard — Nasscom CoE-incubated DronaMaps help combat challenges posed by COVID-19\n",
      "\n",
      "14. Business Standard — UAVs can map better town planning\n",
      "\n",
      "15. Financial Express — Containing Covid-19: Nasscom CoE incubated startups show their mettle\n",
      "\n",
      "16. BusinessLine — Nasscom CoE-incubated start-ups help combat challenges posed by COVID-19\n",
      "\n",
      "17. Elets Egov Magazine — DronaMaps — Deploying drones as geospatial data gathering tool for rural and urban\n",
      "development\n",
      "\n",
      "18. Vogue Magazine — 8 women in STEM who are leading the battle against COVID-19 in India\n",
      "\n",
      "19. Forbes Profile on DronaMaps\n",
      "\n",
      "20. Forbes 30 Under 30 in Enterprise Technology\n",
      "\n",
      "21. Digit Magazine — DronaMaps leverages drone imagery to create large-scale 3D maps\n",
      "\n",
      "22. Indian Express (written by Amitabh Kant, CEO Niti Aayog, Govt of India) - Empowered Groups have joined\n",
      "hands with government against Covid\n",
      "\n",
      "23. Indian Express — Punjab uses cell phone data to fence people in quarantine, track contacts\n",
      "\n",
      "24. DronaMaps Case Study in “India Automated: How the Fourth Industrial Revolution is Transforming India”\n",
      "(written by Pranjal Sharma, WEF advisor)\n",
      "\n",
      "25. Inc 42 — The 12 Amazing Indian Startups Inc42 Discovered During BIGShift\n",
      "\n",
      "26. CNBC TV 18 Interview by Shereen Bhan — India gets its first drone policy: Here is what experts have to say\n",
      "\n",
      "2/. IndiaAl — Interview: Utkarsh Singh, CEO & Founder, DronaMaps on geospatial analysis aiding state\n",
      "governments track COVID19 patients\n",
      "\n",
      "28. ACTGrants — Equipping State War rooms : The Drona Maps Solution\n",
      "\n",
      "29. DigitalTerminal — Punjab Government Makes Public Delivery System Efficient And Transparent With\n",
      "DronaMaps\n",
      "\n",
      "30. ExpressHealthcare.in — Drones, Al helped improve COVID-19 healthcare delivery in Punjab\n",
      "\n",
      "31. NewsPatrolling — Punjab Mandi Board establishes GIS command center with DronaMaps\n",
      "\n",
      "32. Economic Times Government — Punjab Govt use DronaMaps to reach COVID patients in remote areas\n",
      "\n",
      "33. BISInfotech - NASSCOM CoE Incubates DronaMaps during Uttarakhand Floods\n",
      "\n",
      "34. DronaMaps Published Articles on Medium - https://medium.com/dronamaps/latest\n",
      "\n",
      "35. DronaMaps Youtube Channel — https://www. youtube.com/channel/UC-aFzcZb2fi6 Wu0sqRjJUZXQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from documents20220830-1-eq72bl.pdf:\n",
      "ANAM IQBAL\n",
      "Pittsburgh, PA | +1 (646) 207-4431 | anami@andrew.cmu.edu | LinkedIn | Github\n",
      "\n",
      "EDUCATION\n",
      "CARNEGIE MELLON UNIVERSITY (CMU) Pittsburgh, PA\n",
      "Master of Information Systems Management: Business Intelligence & Data Analytics (Focus in Data Science) December 2022\n",
      "\n",
      "Relevant Coursework: Introduction to Deep Learning, Big Data & Large Scale Computing, Unstructured Data Analytics,\n",
      "Machine Learning for Problem Solving, Interactive Data Science, Distributed Systems\n",
      "\n",
      "LAHORE UNIVERSITY OF MANAGEMENT SCIENCES (LUMS) Lahore, Pakistan\n",
      "Bachelor of Science (Honors) - Management Science June 2018\n",
      "\n",
      "SKILLS mn\n",
      "Functional: Machine Learning, Deep Learning, Natural Language Processing (NLP), Artificial Intelligence, A/B Testing, ETL,\n",
      "\n",
      "Data Visualization, Data Engineering, Statistics, Regression, Clustering, Statistical Modeling, Computer Science\n",
      "Languages: Python, SQL, Java, R, Stata\n",
      "\n",
      "Tools: Pandas, NumPy, Scikit-learn, PyTorch, SciPy, TensorFlow, Matplotlib, Git, Tableau, Streamlit, Seaborn,\n",
      "\n",
      "AWS, Spark, Hadoop, Altair, R Shiny, R Markdown, ggplot2, leaflet, Power BI, MS Excel, Jupyter Notebook\n",
      "Business: Collaborative, Attention to Detail, Teamwork, Problem Solving, Organizational Skills, Communication\n",
      "WORK EXPERIENCE\n",
      "HITACHI ENERGY Raleigh, USA\n",
      "Data Science Intern May — August 2022\n",
      "\n",
      "e Drove increased service revenue by creating a supervised + unsupervised machine learning text and numeric matching\n",
      "pipeline in Python that identifies matching features for generator and bus mapping; The pipeline feeds in rough mappings and\n",
      "SME-defined indicators to a Linear Regression model to identify custom weights, which are then used for final calculation\n",
      "score; Improved mapping by 7% as compared to legacy processes and saved hours of tedious manual effort in matching text\n",
      "\n",
      "e Experimented with multiple text matching algorithms like Jaccard Similarity, Levenshtein distance, fuzzy matching and Jaro\n",
      "distances; and text-based features like Parts-of-Speech (POS) tagging and Named Entity Recognition (NER) for text matching\n",
      "\n",
      "e Developed and deployed a first-of-its-kind python-based algorithm design by collating large volumes of data from clients’\n",
      "database/ERP systems, cleaning, transforming it, normalizing it, and calculating complex variables contributing to capacity\n",
      "price forecasting attributes of over 25 years, which helped in making better revenue and investment decisions for power plants\n",
      "\n",
      "e Presented project findings to technical and non-technical stakeholders in a succinct manner and incorporated feedback\n",
      "\n",
      "ENERGY INFORMATICS GROUP, NATIONAL CENTRE IN BIG DATA & CLOUD COMPUTING Lahore, Pakistan\n",
      "Data Analysis Research Associate November 2019 — April 2021\n",
      "e Experimented and prototyped automation of operational dashboard on users’ smart meter activity in 6 different areas of\n",
      "Lahore; eliminated human error and saved 60+ hours of manual effort per month in collecting meter readings via testing\n",
      "\n",
      "e Designed and used A/B testing to optimize the widgets and user experience (UX) of the dashboard\n",
      "\n",
      "e Collaborated with government client to visualize live status updates of neural network based short term load predictive\n",
      "model for Pakistan’s electricity grid and enhanced business performance through online issue reporting efficiency\n",
      "\n",
      "e Created real-time alerting time series classification reporting system, using R Markdown, of electricity consumption at a\n",
      "software company and enabled cost optimization by highlighting unusual energy consumption activity\n",
      "\n",
      "PROJECT EXPERIENCE\n",
      "Disaster Tweet Prediction | project link July — August 2022\n",
      "e Developed a Natural Language Processing (NLP) pipeline which involves text cleaning (removing stop words and\n",
      "punctuations, tokenization, lemmatization), converting text to features, and training a classifier to predict whether a tweet is\n",
      "actually talking about a disaster or not to achieve an F1 score of 79.7% on the Kaggle leaderboard for a novel approach.\n",
      "e Experimented with different techniques like TF-IDF, word2vec, POS tagging, BERT embedding to featurize text.\n",
      "Predict Churning Customers | project link January 2022\n",
      "e Conducted data preprocessing, exploratory analysis, and feature selection for multiple features\n",
      "e Experimented with various classification models and selected the best model using cross-validation based on F1 Score\n",
      "e Evaluated customer churn by using AI model algorithms like XGBoost, Logistic Regression and SVM; finalized on\n",
      "XGBoost ml algorithm with an fl-score of 93% to communicate business strategy and prevent churn\n",
      "Climate Change Tracker | application link January — May 2022\n",
      "e Designed and deployed a novel data science interactive application on visualization software i.e. Streamlit that enables the\n",
      "exploration of multiple climate datasets with interactive visuals and enables users to track the impact of certain hyper\n",
      "parameters on the ml models in real time\n",
      "e The app helps track climate change trends and patterns for countries, enabling preemptive action and improved policy\n",
      "making\n",
      "Calorie and Workout Plan Recommender Application | demo link August — December 2021\n",
      "e Engineered a recommender application in python which helps users determine their calorie intake through API & JSON\n",
      "\n",
      "files, and automatically generates customized weekly meal and workout plans PDF based on metrics using their physical\n",
      "parameters\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from DS Updated 2.pdf:\n",
      "Sachin Asokan\n",
      "\n",
      "asokansachin73@gmail.com Q 7654071650 &§§ in/sachin-asokan-464798183/ « github.com/asokans11\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Industrial Engineering\n",
      "Purdue University - US, Indiana, West Lafayette - 2023 - GPA: 3.6\n",
      "\n",
      "Mechanical Engineering\n",
      "Anna University + India: 2021+ GPA: 3.3\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "Project Lead\n",
      "\n",
      "Dauch Center for the Management of Manufacturing Enterprises August 2022 - May 2023, West Lafayette, United States.\n",
      "- Spearheaded a team of five in creating a supply chain tool to address challenges across 96 counties in Indiana, empowering customers to access regional\n",
      "product information.\n",
      "\n",
      "- Leveraged ETL processes to assess and verify the accuracy of company data, maintaining a well-organized MySQL database.\n",
      "\n",
      "- Implemented web scraping techniques with ParseHub to streamline the data gathering phase of the ETL process, reducing data collection time by 50%.\n",
      "\n",
      "- Provided mentorship and guidance to junior team members, leading to a 25% increase in team productivity and a significant improvement in individual skill\n",
      "sets over the course of the project.\n",
      "\n",
      "- Collaboratively defined project goals and established strategic plans with the team, ensuring a clear vision and direction that led to successful project\n",
      "completion and improved overall team performance.\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "Bayer August 2022 - December 2022, West Lafayette, United States.\n",
      "- Project in Collaboration with Bayer and Purdue University.\n",
      "\n",
      "- Handled missing data in genetic marker datasets by implementing zero imputation, enhancing the accuracy and reliability of subsequent predictive analysis\n",
      "for phenotypic traits.\n",
      "\n",
      "- Implemented a data pipeline that divided imputed marker datasets by population generating insights and analysis on per population basis.\n",
      "\n",
      "- Constructed a new SQL database on cluster 2, integrating both imputed marker and phenotypic data. This Standardized data repository supported efficient\n",
      "data retrieval and analysis.\n",
      "\n",
      "- Developed Mixed Linear model to predict yield utilizing features such as Genetic markers and environmental features achieving an r-squared value of 0.2.\n",
      "\n",
      "Data Analyst\n",
      "\n",
      "Wabash National July 2022 - August 2022, West Lafayette, Indiana\n",
      "- Project in Collaboration with Purdue and Wabash National.\n",
      "\n",
      "- Conducted univariate exploratory data analysis on telematics data for Wabash trucks across the United States.\n",
      "\n",
      "- Established geofences around 70+ distribution centers for geospatial analysis, monitoring inventory levels over three years to drive informed business\n",
      "decisions.\n",
      "\n",
      "- Optimized parallel processing pipelines using Dask and Python for handling large dataset of size over 100 GB, achieving an 85% reduction in storage levels.\n",
      "\n",
      "- Communicated key findings to stakeholders using Data Visualization techniques such as Tableau, Matplotlib and Seaborn and influenced key business\n",
      "decisions by optimizing inventory with a projected annual profit of five percent. Documented Project metrics, results, business objectives and outcomes.\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Amazon Sentiment Analysis (NLP, Unstructured Data)\n",
      "\n",
      "- Developed and Executed a Bidirectional GRU neural network model to conduct sentiment analysis on a robust dataset of Amazon product reviews to\n",
      "investigate consumer feedback to bring business impact and recommend solutions to improve systems.\n",
      "\n",
      "- Streamlined data preprocessing by leveraging FastText for effective text encoding of review data, leading to an impressive classification accuracy of 90%,\n",
      "demonstrating the model's high performance and reliability in sentiment prediction.\n",
      "\n",
      "Object Detection and Localization (Computer Vision)\n",
      "\n",
      "- Crafted a ResNET architecture boasting 98 layers and 150 million parameters, featuring cross entropy and IOU loss functions to enable precise object detection\n",
      "and localization with an impressive 90% accuracy rate.\n",
      "\n",
      "- Solved Vanishing Gradient problem by employing Skip Blocks.\n",
      "\n",
      "Parkinson’s Disease Classification (Predictive Modeling, Structured Data)\n",
      "\n",
      "- Tackled class imbalance issues by implementing Borderline SMOTE and utilized classification algorithms like Random Forests and SVM, resulting in high\n",
      "precision and recall of 0.93.\n",
      "\n",
      "- Minimized false-negative rates to near-zero levels, significantly enhancing prediction quality and achieved a classification accuracy of 98 percent.\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Programming: C++, Arduino, Python, R\n",
      "\n",
      "Libraries: PyTorch, TensorFlow, Keras, Scikit-Learn, Statsmodels, Scipy, Pandas, Dask, Numpy.\n",
      "Database: Postgres SQL, MySQL.\n",
      "\n",
      "BI Tools: Tableau.\n",
      "\n",
      "Visualization: Matplotlib, Seaborn, Geopy, Geopandas, Plotly, Folium.\n",
      "\n",
      "Cloud: AWS\n",
      "\n",
      "Algorithms: Regression, Classification, Clustering, Deep Learning and Time Series.\n",
      "\n",
      "Mathematical Core: Statistics and Probability, Linear Algebra, Multivariate Calculus, Optimization.\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from Januka Pandey Gautam.pdf:\n",
      "Januka Pandey Gautam\n",
      "\n",
      "Big Data Engineer\n",
      "Januka.pandey456@gmail.com | 929-251-4811\n",
      "\n",
      "httos://www.linkedin.com/in/januka-pandey\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "e Over 5+ years of IT experience as a Developer, Designer & quality Tester with cross platform integration experience\n",
      "using Hadoop development and Admin.\n",
      "\n",
      "e Firsthand experience in installing, configuring, and using Hadoop Ecosystem - HDFS, MapReduce, Pig, Hive, Oozie,\n",
      "Flume, HBase, Spark, Sqoop, Flume and Oozie.\n",
      "\n",
      "e Strong understanding of various Hadoop services, MapReduce, and YARN architecture.\n",
      "\n",
      "e Responsible for writing Map Reduce programs.\n",
      "\n",
      "e Experienced in importing-exporting data into HDFS using SQOOP.\n",
      "\n",
      "e Experience loading data to Hive partitions and creating buckets in Hive.\n",
      "\n",
      "e Developed Map Reduce jobs to automate transfer the data from HBase.\n",
      "\n",
      "e Expertise in analysis using PIG, HIVE and MapReduce.\n",
      "\n",
      "e Experience in HDFS data storage and support for running map-reduce jobs.\n",
      "\n",
      "e Experience in big data technologies: Hadoop HDFS, Map-reduce, Pig, Hive, Oozie, Sqoop, Zookeeper and NoSQL.\n",
      "\n",
      "e Responsible for the Provisioning, installing, configuring, monitoring, and maintaining HDFS, Yarn, HBase, Flume,\n",
      "Sqoop, Oozie, Pig, Hive, Ranger, Falcon, Smart sense, Storm, Kafka.\n",
      "\n",
      "e Experience in AWS CloudFront, including creating and managing distributions to provide access to S3 bucket or\n",
      "HTTP server running on EC2 instances.\n",
      "\n",
      "e Experience in gathering and defining functional and user interface requirements for software applications.\n",
      "\n",
      "e Experience in real time analytics with Apache Spark (RDD, Data Frames and Streaming API).\n",
      "\n",
      "e Used Spark Data Frames API over Cloudera platform to perform analytics on Hive data.\n",
      "\n",
      "e Experience in integrating Hadoop with Kafka. Expertise in uploading Click stream data from Kafka to HDFS.\n",
      "\n",
      "e =Expert in utilizing Kafka for messaging and publishing subscribe messaging system.\n",
      "\n",
      "Core Competencies:\n",
      "\n",
      "Python 2.7.x and Python 3.x, SQL, PL/SQL, Shell Scripting, Storm 1.0, JSP, Servlets,\n",
      "Scala, Python, Java, R, JavaScript\n",
      "\n",
      "Hadoop, HDFS, Map Reduce, HBase, Apache Pig, Hive, Sqoop, Apache Impala,\n",
      "Oozie, Yarn, Apache Flume, Kafka, Zookeeper\n",
      "\n",
      "Linear Regression, Ridge Regression, Polynomial Regression, Lasso Regression,\n",
      "Elastic Net\n",
      "\n",
      "Clustering k-Means, Hierarchical Clustering, Latent Dirichlet Allocation (LDA)\n",
      "Cloud Platform Amazon Web Services, Microsoft Azure\n",
      "Version Control: GIT, SVN, CVS\n",
      "\n",
      "Education Details\n",
      "Capella University\n",
      "Bachelors in Information Technology\n",
      "\n",
      "Career Experiences:\n",
      "\n",
      "AT&T, New York, NY Jun 2020 - Present\n",
      "Big Data Engineer\n",
      "\n",
      "Responsibilities:\n",
      "e Responsible for modeling complex Institute problems, discovering insights and identifying opportunities with\n",
      "statistical, algorithmic, mining and visualization techniques.\n",
      "\n",
      "Proficient at integrating and preparing large, varied datasets, designing specialized database and computing\n",
      "environments, and communicating results.\n",
      "\n",
      "Developed the new Spark jobs using Scala, to run on the HDP clusters, which provided significant gains on the\n",
      "completion times. Design development of Spark SQL Scripts based on Functional Specifications\n",
      "\n",
      "Responsible for Spark Streaming configuration based on type of Input Source\n",
      "\n",
      "Apache Kafka Streaming API for ingesting the data to Spark Streams and also publish to Kafka Topics for publishing\n",
      "the anomaly\n",
      "\n",
      "Importing and exporting data into HDFS and HIVE, PIG using Spark and Arttunity and Sqoop\n",
      "\n",
      "Used Dynamic partition for Hive when loading data. Implemented External and Hive managed Tables for significant\n",
      "performance gains.\n",
      "\n",
      "Involved in creating Hive Tables, loading with data and writing Hive queries which will invoke and run Spark jobs in\n",
      "the backend.\n",
      "\n",
      "Writing Spark (Hadoop) programs to convert text files into AVRO and loading into Hive (Hadoop) tables\n",
      "Implemented the workflows using Apache Oozie Spark library to automate tasks.\n",
      "\n",
      "Worked with NoSQL databases like HBase, MongoDB in creating HBase tables to load large sets of semi structured\n",
      "data coming from various sources.\n",
      "\n",
      "Used Hive and created Hive tables and involved in data loading and writing Hive UDFs.\n",
      "\n",
      "Responsible for spooling data from DB2 sources to HDFS using sqoop.\n",
      "\n",
      "Created HIVE tables and provided analytical queries for business user analysis\n",
      "\n",
      "Extensive knowledge on PIG scripts using bags and tuples.\n",
      "\n",
      "Created tables in HIVE by partitioning and bucketing for granularity and optimization of HIVEQL.\n",
      "\n",
      "Northern Trust, Chicago , IL Apr 2017 - Mar 2020\n",
      "Big Data Engineer\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Installed and configured Hadoop MapReduce, HDFS, Developed multiple MapReduce jobs in java for data cleaning\n",
      "and processing.\n",
      "\n",
      "Importing and exporting data into HDFS, Pig, Hive and HBase using Sqoop.\n",
      "\n",
      "Managing and reviewing Hadoop log files.\n",
      "\n",
      "Worked on loading and transformation of large sets of structured, semi structured and unstructured data into\n",
      "Hadoop system.\n",
      "\n",
      "Responsible to manage data coming from different data sources.\n",
      "\n",
      "Developed simple and complex MapReduce programs for Data Analysis.\n",
      "\n",
      "Load data from various data sources into HDFS using Flume.\n",
      "\n",
      "Implemented Partitioning, Dynamic Partitions, Buckets in HIVE.\n",
      "\n",
      "Developed Java MapReduce programs for the analysis of sample log file stored in cluster.\n",
      "\n",
      "Involved in identifying job dependencies to design workflow for Oozie and resource management for YARN\n",
      "Capturing data from existing databases that provide SQL interfaces using Sqoop.\n",
      "\n",
      "Efficient in building pig, hive and map-reduce scripts.\n",
      "\n",
      "Cluster coordination services through Zoo Keeper.\n",
      "\n",
      "Involved in loading data from UNIX file system to HDFS.\n",
      "\n",
      "Installed and configured Pig, Hive and also written Pig and Hive UDFs.\n",
      "\n",
      "Automated all the jobs, for pulling data from FTP server to load data into Hive tables, using Oozie workflows.\n",
      "Involved in creating Hive tables, loading with data and writing hive queries which will run internally in map way.\n",
      "Exported analyzed data to relational databases using Sqoop for visualization to generate reports for the BI team.\n",
      "\n",
      "References Available Upon Request\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from Maaz khan _ d17.pdf:\n",
      "Maaz Muhammad Khan\n",
      "maazkhan1211@gmail.com | (216)-666-095|\n",
      "Education ———SSSSSSSSSSSSSSSSSSSSSSSS....W(.__\n",
      "M.S. Computer Science (GPA 3.77) January 2020 —December 2021\n",
      "Cleveland State University\n",
      "\n",
      "Relevant Coursework: Data Mining, Big data, Machine Learning, Artificial Intelligence, Data communication and Networks\n",
      "\n",
      "B.S. Computer Science (GPA 3.39) January 2015 — December 2018\n",
      "Muhammad Ali Jinnah University\n",
      "\n",
      "Relevant Coursework: Database Systems, Cloud Computing, Statistics, Algorithms and Data Structures, Object Oriented Programming,\n",
      "\n",
      "Human Computer Interaction, Web Development, Computer Architecture, Software Requirement Engineering, Software Quality Assurance\n",
      "\n",
      "Work Experience\n",
      "\n",
      "Business Intelligence Analyst\\Data Engineer Jan 2022-Present\n",
      "New York Air Brake, Watertown, NY\n",
      "¢ Designed & developed visual BI reports and dashboards to support management decision-making using Power bi and Tableau.\n",
      "¢ Developed and automated data pipelines and ETL process and deployed new data models to make datasets readily-consumable by visualization tools\n",
      "using Snowflake and SQL Server.\n",
      "¢ Drove efficiencies throughout the organization by automating business processes.\n",
      "¢ Gathered and analyzed data from multiple sources to solve complex problems and prepared summaries of analysis and findings to management team.\n",
      "¢ Worked with leadership to understand business needs and translate those into reporting solutions.\n",
      "¢ Promoted the adoption of Business Intelligence tools throughout the organization\n",
      "¢ Developed and maintain data quality standards and data governance policies.\n",
      "Systems Administrator May 2019 — Jan 2022\n",
      "Lansing Board of Water and Light, Lansing, MI\n",
      "¢ Designed and developed dashboards which helped managers in making critical decisions to drive employee productivity and resource utilization.\n",
      "° Created dashboards with context and overlayed analytics and live, interactive, reports that easily compare and analyze assets using Microsoft Power-Bi\n",
      "e Managed server, data repositories and the real-time data storage, normalization, analytics, and notification engine using Microsoft Azure SQL database.\n",
      "¢ Summarized and filtered years of historical data and view alongside real-time data which allowed summary calculations\n",
      "¢ Used python and SQL for ETL processes data cleansing, normalization, and transformation for operations analytics project.\n",
      "¢ — Also used Microsoft Azure DevOps for version control, reporting, requirements management, project management, automated builds, testing and release\n",
      "management capabilities for the entire application lifecycle(Agile Methodology).\n",
      "¢ Worked on real-time data from grid and network devices for data analytics and applied machine learning to automate network response.\n",
      "Research Assistant Feb 2020 — April 2021\n",
      "Artificial Intelligence and Computer Vision Lab, Cleveland State University, Cleveland, OH.\n",
      "¢ Collected dataset by web scraping techniques using libraries like selenium, beautiful soup, and response.\n",
      "¢ Stored unstructured using Pymongo and did preprocessing/cleansing using Sk.learn and Opencv, numpy, pandas , skiamge\n",
      "¢ Sliced data using Sklearn.model selection for testing and training and added layers filters and activation to convolutional neural networks.\n",
      "¢ Transformed data and developed a system which classifies images into subcategories with the help of cnn using Pytorch & Torchvision\n",
      "° Extracted features from datasets using ICA, LBP, Hog, PCA , LDA, LLE, AE, and etc.\n",
      "¢ Applied machine learning models like, CNN, KNN, Kmeans, SVM, Naive Bayes, Regression, Gradient Boosting Algorithms\n",
      "¢ Determined the hidden relation between images and text using text and image mining libraries NItk and Gensim\n",
      "¢ Worked on image recognition using Tensorflow and Keras for implementation of (CNN) with different initializers like Adam and SGD.\n",
      "Data analyst/Enginer May 2016 — July 2020\n",
      "John Carroll University, Cleveland, OH\n",
      "¢ — Assisted data scientists in building sentiment analysis and Used python and SQL for text mining and artificial intelligence techniques.\n",
      "¢ Extracted data from web sources using scraping and web crawling in python and created text corpora & SQL scripts & analyzed the data in MS Excel.\n",
      "¢ Analyzed complex data sets and translated data into insights to drive key business decisions using Tableau and Microsoft Power BI.\n",
      "¢ Implemented data mining and analytics solutions to various business problems.\n",
      "¢ Mined huge textual dataset of online reviews of different movies using NLTk and Genism and Categorized data into POS, removed stop words\n",
      "¢ Then, lemmatized and stemmed words & ran LDA model using Spacy and Genism and then calculated perplexity and coherence score.\n",
      "Technical Skills\n",
      "¢ Analytic Development: Python, R-programming, MATLAB, SQL, C, C++, C#, HTML, CSS, Java, XML\n",
      "° BI tools: Tableau, Microsoft Power BI, Power Query, DAX SAP Analytics Looker, Google Charts, Qlik, SSRS, SSIS\n",
      "° Cloud Services: AWS, Azure and Google Cloud, Snowflake, Informatica\n",
      "¢ Miscellaneous Tools: SAP SAC, JIRA, Azure DevOps, SharePoint MS-Teams.\n",
      "\n",
      "¢ Artificial Intelligence & Analysis Methods:: Text comprehension, NLP, Classification, Pattern Recognition, Imaging Recognition and\n",
      "\n",
      "Detection, forecasting, clustering, Sentiment Analysis, Predictive Analytics, Decision Analytics, Association Analysis, Attribution modeling,\n",
      "Classification and Regression Trees (CART), SVM, Random Forest, GBM,, PCA, RNN, Regression, Naive Bayes\n",
      "\n",
      "¢ Data Modeling: Bayesian Analysis, Statistical Inference, Predictive Modeling, Stochastic Modeling, Linear Modeling, Behavioral Modeling\n",
      "\n",
      "° Python Packages: NumPy, Pandas, Scikit-learn, TensorFlow, SciPy, Matplotlib, Seaborn, Keras, NLTK, Beautiful Soup, SciPy, StatsModels,\n",
      "PyTorch, OpenCV, Sweetviz, Theano, Bokeh, Plotly, Genism, Scrapy, kivy, Caffe2\n",
      "\n",
      "¢ IDE & Version Control: Jupyter Notebook, Spyder, RStudio, Visual Studio, SharePoint, A/B testing GitHub, Git, Agile methodologies\n",
      "\n",
      "¢ Databases: Oracle, MS SQL Server, Snowflake, MS Access Amazon S3, Azure, Mongo DB , My SQL, PostgreSQL and Hadoop, Pyspark .\n",
      "\n",
      "¢ Soft Skills: Communication and presentation skills; teamwork; leadership, critical thinking, creativity, and problem-solving, accountability.\n",
      "\n",
      "\n",
      "\n",
      "Text extracted from Maximillian Wiesner.pdf:\n",
      "Maximillian Wiesner\n",
      "\n",
      "maxanth112@gmail.com\n",
      "(949) 636-9002\n",
      "\n",
      "San Diego, CA\n",
      "\n",
      "Versatile data engineer who likes breaking things, fixing things, and occasionally asking too many questions. No\n",
      "particular order.\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "SIGNPOST San Diego, CA\n",
      "Data Engineer (Remote) Aug 21’-Current\n",
      "\n",
      "e Sole data engineer for a Series D startup with a distributed engineer team out of New York and Denver.\n",
      "Have implemented new ETL pipelines, optimized existing ones, and maintain the existing data\n",
      "infrastructure. Role has been a mix of data engineering (70%), devops (20%), and machine learning (10%). |\n",
      "wear many hats in this position, working closely with our infrastructure engineers, devops engineers,\n",
      "business operations team, BI analysts, and PM’s.\n",
      "\n",
      "e Evangelized Airflow as our new workflow management system and migrated all previous data sync jobs off\n",
      "Jenkins. Transferring some jobs to Airflow, and others into docker images running in various ECS clusters.\n",
      "\n",
      "e Integrated new batch/stream data pipelines with third party applications like HubSpot, Braze,\n",
      "\n",
      "Paycom, YouCanBookMe, Gainsight and more.\n",
      "\n",
      "e Built a random forest classifier and predicted customer churn with 93% accuracy, highlighting the\n",
      "most impactful business features to mitigate future drop out (we are a subscription-based\n",
      "service).\n",
      "\n",
      "e Responsible for the health, speed, and availability of the warehouse; as well as managing users,\n",
      "permissions, and product data views used for internal reporting.\n",
      "\n",
      "Tools: Redshift, RDS, EC2, ECS, Docker, Airflow, Jenkins, Mode, Ubuntu, CloudFormation, CircleCl\n",
      "\n",
      "FRONTIER AIRLINES Denver, CO\n",
      "Analytics Developer (Remote) Jan 20’-May 21’\n",
      "\n",
      "e Cleaned/authored database tables, created views for internal reporting, and maintained numerous data\n",
      "pipelines for engineering, finance, and operations.\n",
      "\n",
      "e Created KPIs and other trackable performance metrics for individual teams to use daily. KPls addressed\n",
      "overall department performance, internal top performers (on teams where this was trackable), outstanding\n",
      "orders, and advised overall inventory volume, and spend.\n",
      "\n",
      "e Used the Microsoft cloud suite to automate tasks, publish/email KPls, trigger purchase orders, and optimize\n",
      "inventory allocation defined by a self-baked regression model which looked at historical maintenance data.\n",
      "\n",
      "Tools: Microsoft Azure, PowerApps, Power BI, Microsoft SQL Server, Jupyter Hub\n",
      "\n",
      "Data Analyst Jan 19’-Jan 20’\n",
      "\n",
      "e Bl reporting machine on the technical and material operations team in the engineering department.\n",
      "\n",
      "e Was given a manually calculated copy and paste excel report, produced the same report within Power BI, set\n",
      "the refresh and notification schedule, rinse, repeat.\n",
      "\n",
      "e Projected inventory planning across 8 class 2 stations (most traffic), and 20+ class 3 locations to minimize\n",
      "aircraft maintenance downtime.\n",
      "\n",
      "Tools: Power BI, Microsoft SQL Server, Jupyter Hub\n",
      "\n",
      "EXPERIMENTAL MATHEMATICS LAB - CU BOULDER Boulder, CO\n",
      "Undergraduate Researcher Jan 20’-May 20’\n",
      "\n",
      "e Participated on a team of 5 undergraduate mathematics students on a semester long number theory\n",
      "research project exploring the Collatz Conjecture.\n",
      "\n",
      "e We looked at the problem through a computational lens, as well as its consequences in p-adic space,\n",
      "differential equations, and various parts of analysis. | focused on the stopping time of the sequence, trying\n",
      "to explain its (alleged) limiting asymptotic density.\n",
      "\n",
      "Tools: MATLAB, Jupyter Hub\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "UNIVERSITY OF COLORADO AT BOULDER\n",
      "\n",
      "Master of Science in Computer Science [software Systems & Cloud Computing Focus] Aug 21°-May 22\n",
      "Activities & Societies: Completed the two-year program in one while working full-time, there was no time (motivation?)\n",
      "for these.\n",
      "\n",
      "UNIVERSITY OF COLORADO AT BOULDER\n",
      "\n",
      "Bachelor of Science in Computer Science Jan 20’-May 21’\n",
      "Bachelor of Arts in Mathematics [Computational Track] Jan 20’-May 21’\n",
      "Bachelor of Arts in Economics [International Emphasis] Aug 15’-May 19°\n",
      "\n",
      "Activities & Societies: CU Men’s Lacrosse, CAPA Florence Study Abroad Semester, Sigma Phi Epsilon, Hack CU —\n",
      "Hackathon participant for 2 years, Econ Club, Math Club (QED).\n",
      "\n",
      "ABOUT ME/OTHER\n",
      "\n",
      "e |’ve been a youth lacrosse coach for a few years, running offensive practices for juniors/seniors in summer club ball for\n",
      "the Colorado Fire team. In high school | was a 2x varsity captain and all-state as a sophomore-senior. At CU | got MCLA D1\n",
      "player of the week my first week of games as a freshman; | immediately peaked unfortunately.\n",
      "\n",
      "e Amcurrently restoring a 70’ Ford Bronco and a’78 BMW R100RS, very slowly. | try and build things every so often,\n",
      "weather its auto/moto, woodworking, or applications.\n",
      "\n",
      "e | enjoy traveling, bikes of any degree, doing nothing at the beach/park with friends (we call it rotting), consuming books\n",
      "at irregular intervals, making a leisurely espresso in the morning, and drawing on my chalk board. | strive for originality in\n",
      "everything | do and find peoples passions contagious and motivating. | am always looking for new opportunities to learn,\n",
      "create, and round myself and my experiences.\n",
      "\n",
      "e Resume website | made before | knew what a JavaScript framework was: https://maxwiesner.github.io/Portfolio\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Check if the file is a PDF\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     text_from_file \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Check if the file is a DOCX\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32md:\\Mined 24\\Mined Hackathon\\TXT.py:15\u001b[0m, in \u001b[0;36mDocumentConverter.extract_text_from_pdf\u001b[1;34m(self, pdf_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_pdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, pdf_path):\n\u001b[1;32m---> 15\u001b[0m     pages \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     text_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n",
      "File \u001b[1;32mc:\\Users\\devba\\miniconda3\\Lib\\site-packages\\pdf2image\\pdf2image.py:251\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid, proc \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m         data, err \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired:\n\u001b[0;32m    253\u001b[0m         proc\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mc:\\Users\\devba\\miniconda3\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\devba\\miniconda3\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\devba\\miniconda3\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\devba\\miniconda3\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Your existing DocumentConverter class and its methods here...\n",
    "\n",
    "# Create an instance of DocumentConverter\n",
    "converter = DocumentConverter()\n",
    "# print(converter.extract_text_from_pdf(\"D:\\Mined 24\\Resume\\Resume(1).pdf\"))\n",
    "\n",
    "# Directory containing the resumes\n",
    "resumes_directory = \"D:\\Mined 24\\Resume\"\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(resumes_directory):\n",
    "    file_path = os.path.join(resumes_directory, filename)\n",
    "    \n",
    "    # Check if the file is a PDF\n",
    "    if filename.endswith('.pdf'):\n",
    "        text_from_file = converter.extract_text_from_pdf(file_path)\n",
    "    \n",
    "    # Check if the file is a DOCX\n",
    "    elif filename.endswith('.docx'):\n",
    "        text_from_file = converter.extract_text_from_docx(file_path)\n",
    "    \n",
    "    # Check if the file is an HTML\n",
    "    elif filename.endswith('.html'):\n",
    "        text_from_file = converter.extract_text_from_html(file_path)\n",
    "    elif filename.endswith('.doc'):\n",
    "        text_from_file = converter.extract_text_from_doc(file_path)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Unsupported file format: {filename}\")\n",
    "        continue  # Skip to the next file if the format is not supported\n",
    "    \n",
    "    # Print or save the extracted text\n",
    "    print(f\"Text extracted from {filename}:\\n{text_from_file}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
